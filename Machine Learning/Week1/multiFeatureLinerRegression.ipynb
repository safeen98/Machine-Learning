{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc93aec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy , math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(precision=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f904d4",
   "metadata": {},
   "source": [
    "2 Problem Statement\n",
    "You will use the motivating example of housing price prediction. The training dataset contains three examples with four features (size, bedrooms, floors and, age) shown in the table below. Note that, unlike the earlier labs, size is in sqft rather than 1000 sqft. This causes an issue, which you will solve in the next lab!\n",
    "\n",
    "Size (sqft)\tNumber of Bedrooms\tNumber of floors\tAge of Home\tPrice (1000s dollars)\n",
    "2104\t5\t1\t45\t460\n",
    "1416\t3\t2\t40\t232\n",
    "852\t2\t1\t35\t178\n",
    "You will build a linear regression model using these values so you can then predict the price for other houses. For example, a house with 1200 sqft, 3 bedrooms, 1 floor, 40 years old.\n",
    "\n",
    "Please run the following code cell to create your X_train and y_train variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "592b1603",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "Y_train = np.array([460, 232, 178])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c720b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train : (3, 4) and its type is <class 'numpy.ndarray'>\n",
      "shape of Y_train : (3,) and its type is <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape of X_train : {X_train.shape} and its type is {type(X_train)}\")\n",
    "print(f\"shape of Y_train : {Y_train.shape} and its type is {type(Y_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39f3791",
   "metadata": {},
   "source": [
    "2.2 Parameter vector w, b\n",
    "𝐰\n",
    "  is a vector with  𝑛\n",
    "  elements.\n",
    "Each element contains the parameter associated with one feature.\n",
    "in our dataset, n is 4.\n",
    "notionally, we draw this as a column vector\n",
    "𝐰=𝑤0𝑤1⋯𝑤𝑛−1\n",
    " \n",
    "\n",
    "𝑏\n",
    "  is a scalar parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "339242bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_init shape: (4,), b_init type: <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "b_init = 785.1811367994083\n",
    "w_init = np.array([ 0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
    "print(f\"w_init shape: {w_init.shape}, b_init type: {type(b_init)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48431158",
   "metadata": {},
   "source": [
    "3.2 Single Prediction, vector\n",
    "Noting that equation (1) above can be implemented using the dot product as in (2) above. We can make use of vector operations to speed up predictions.\n",
    "\n",
    "Recall from the Python/Numpy lab that NumPy np.dot()[link] can be used to perform a vector dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a73903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,w,b):\n",
    "    pred = np.dot(x,w) + b\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57d3be3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_vec : (4,) and its type is <class 'numpy.ndarray'>\n",
      "The predicted value is 459.9999976194083\n"
     ]
    }
   ],
   "source": [
    "x_vec = X_train[0]\n",
    "print(f\"shape of x_vec : {x_vec.shape} and its type is {type(x_vec)}\")\n",
    "\n",
    "f_wb = predict(x_vec , w_init , b_init)\n",
    "print(f\"The predicted value is {f_wb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18613b7",
   "metadata": {},
   "source": [
    "4 Compute Cost With Multiple Variables¶\n",
    "The equation for the cost function with multiple variables  𝐽(𝐰,𝑏)\n",
    "  is:\n",
    "𝐽(𝐰,𝑏)=12𝑚∑𝑖=0𝑚−1(𝑓𝐰,𝑏(𝐱(𝑖))−𝑦(𝑖))2(3)\n",
    "where:\n",
    "𝑓𝐰,𝑏(𝐱(𝑖))=𝐰⋅𝐱(𝑖)+𝑏(4)\n",
    "\n",
    "In contrast to previous labs,  𝐰\n",
    "  and  𝐱(𝑖)\n",
    "  are vectors rather than scalars supporting multiple features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95411164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(x,y,w,b):\n",
    "    m = x.shape[0]\n",
    "    cost = 0\n",
    "    for i in range(m):\n",
    "        f_wb = np.dot(x[i],w) + b\n",
    "        cost = cost + (f_wb - y[i])**2\n",
    "    cost = cost / (2*m)\n",
    "    return cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d45f8244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at optimal w : 1.5578904045996674e-12\n"
     ]
    }
   ],
   "source": [
    "cost = compute_cost(X_train, Y_train, w_init, b_init)\n",
    "print(f'Cost at optimal w : {cost}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3964ae51",
   "metadata": {},
   "source": [
    "5 Gradient Descent With Multiple Variables\n",
    "Gradient descent for multiple variables:\n",
    "\n",
    "repeat} until convergence:{𝑤𝑗=𝑤𝑗−𝛼∂𝐽(𝐰,𝑏)∂𝑤𝑗𝑏  =𝑏−𝛼∂𝐽(𝐰,𝑏)∂𝑏for j = 0..n-1(5)\n",
    "\n",
    "where, n is the number of features, parameters  𝑤𝑗\n",
    " ,  𝑏\n",
    " , are updated simultaneously and where\n",
    "\n",
    "∂𝐽(𝐰,𝑏)∂𝑤𝑗∂𝐽(𝐰,𝑏)∂𝑏=1𝑚∑𝑖=0𝑚−1(𝑓𝐰,𝑏(𝐱(𝑖))−𝑦(𝑖))𝑥(𝑖)𝑗=1𝑚∑𝑖=0𝑚−1(𝑓𝐰,𝑏(𝐱(𝑖))−𝑦(𝑖))(6)(7)\n",
    "\n",
    "m is the number of training examples in the data set\n",
    "𝑓𝐰,𝑏(𝐱(𝑖))\n",
    "  is the model's prediction, while  𝑦(𝑖)\n",
    "  is the target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee92ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(x,y,w,b):\n",
    "    m,n = x.shape #m is the number of examples and n is the number of features\n",
    "    dw_dj =np.zeros(n)\n",
    "    db_dj = 0\n",
    "    for i in range(m):\n",
    "        err = (np.dot(x[i],w) +b) - y[i]\n",
    "        for j in range(n):\n",
    "            dw_dj[j] = dw_dj[j]  + err * x[i,j]\n",
    "        db_dj = db_dj + err\n",
    "    dw_dj = dw_dj/m\n",
    "    db_dj = db_dj/m\n",
    "    return dw_dj ,db_dj "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "848dbf26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db at initial w,b: -1.6739251122999121e-06\n",
      "dj_dw at initial w,b: \n",
      " [-2.73e-03 -6.27e-06 -2.22e-06 -6.92e-05]\n"
     ]
    }
   ],
   "source": [
    "tmp_dj_dw ,tmp_dj_db = compute_gradient(X_train, Y_train, w_init, b_init)\n",
    "print(f'dj_db at initial w,b: {tmp_dj_db}')\n",
    "print(f'dj_dw at initial w,b: \\n {tmp_dj_dw}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
